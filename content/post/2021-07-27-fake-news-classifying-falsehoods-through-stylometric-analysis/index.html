---
title: 'FAKE NEWS: How we can stem the spread of fake news through machine learning'
author: Zachary Haroian
date: '2021-07-27'
slug: fake-news-classifying-falsehoods-through-stylometric-analysis
bibliography: bibliography.bib
csl: apa.csl
categories: []
tags: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>
<script src="{{< blogdown/postref >}}index_files/htmlwidgets/htmlwidgets.js"></script>
<script src="{{< blogdown/postref >}}index_files/plotly-binding/plotly.js"></script>
<script src="{{< blogdown/postref >}}index_files/typedarray/typedarray.min.js"></script>
<script src="{{< blogdown/postref >}}index_files/jquery/jquery.min.js"></script>
<link href="{{< blogdown/postref >}}index_files/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="{{< blogdown/postref >}}index_files/crosstalk/js/crosstalk.min.js"></script>
<link href="{{< blogdown/postref >}}index_files/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="{{< blogdown/postref >}}index_files/plotly-main/plotly-latest.min.js"></script>


<p><img src="images/fake-news-hero-img.jpg" /></p>
<div id="the-problem" class="section level1">
<h1>The Problem</h1>
<p>Fake news is seeping its way into society, spreading falsehoods and manipulating its readers through fear and urgency. Fake news is defined as fabricated information that mimics news media content without the editorial norms and processes for ensuring accuracy and credibility of information <span class="citation">(<a href="#ref-lazer_2018" role="doc-biblioref">Lazer et al., 2018</a>)</span>. It is parasitic on standard news outlets, both benefiting from and undermining their credibility.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/news-consumption-1.png" width="40%" style="float:right; padding:0px" /></p>
<p>Social media platforms act as a key conduit for fake news sites, as the ease of creating fake profiles makes impersonation trivial <span class="citation">(<a href="#ref-allcott_2017" role="doc-biblioref">Allcott &amp; Gentzkow, 2017</a>)</span>. About 67% of Americans report getting news from social media <span class="citation">(<a href="#ref-shearer_2017" role="doc-biblioref">Shearer &amp; Gottfried, 2017</a>)</span>. In fact, the most popular fake news stories in the last three months of the presidential campaign generated more engagement on Facebook than the top real news stories.</p>
<p>The rise of fake news is recent, but is not a novel occurrence. After the widespread use of propaganda in World War I, journalists moved to be more objective and focused on building public trust and credibility. This trust has been severely eroded due to the internet, where the competition has a much lower cost of entry to distribute information. What was once gatekept by large news corporations can now be done by anyone with a computer and an internet connection. The lack of trust in news reached a historic low in 2016, with 51% of Democrats and 14% of Republicans expressing “a fair amount” or “a great deal” of trust in mass media as a news source <span class="citation">(<a href="#ref-swift_2016" role="doc-biblioref">Swift, 2016</a>)</span>.</p>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"data":[{"x":["1997-01-01","1998-01-01","1999-01-01","2000-01-01","2001-01-01","2002-01-01","2003-01-01","2004-01-01","2005-01-01","2007-01-01","2008-01-01","2009-01-01","2010-01-01","2011-01-01","2012-01-01","2013-01-01","2014-01-01","2015-01-01","2016-01-01"],"y":[64,59,61,53,65,59,66,59,70,66,60,58,59,56,58,60,54,55,51],"text":["1997<br />Democrats<br />Trust: 64%","1998<br />Democrats<br />Trust: 59%","1999<br />Democrats<br />Trust: 61%","2000<br />Democrats<br />Trust: 53%","2001<br />Democrats<br />Trust: 65%","2002<br />Democrats<br />Trust: 59%","2003<br />Democrats<br />Trust: 66%","2004<br />Democrats<br />Trust: 59%","2005<br />Democrats<br />Trust: 70%","2007<br />Democrats<br />Trust: 66%","2008<br />Democrats<br />Trust: 60%","2009<br />Democrats<br />Trust: 58%","2010<br />Democrats<br />Trust: 59%","2011<br />Democrats<br />Trust: 56%","2012<br />Democrats<br />Trust: 58%","2013<br />Democrats<br />Trust: 60%","2014<br />Democrats<br />Trust: 54%","2015<br />Democrats<br />Trust: 55%","2016<br />Democrats<br />Trust: 51%"],"type":"scatter","mode":"lines+markers","line":{"width":1.88976377952756,"color":"rgba(0,21,188,1)","dash":"solid"},"hoveron":"points","name":"Democrats","legendgroup":"Democrats","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","marker":{"autocolorscale":false,"color":"rgba(0,21,188,1)","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,21,188,1)"}},"frame":null},{"x":["1997-01-01","1998-01-01","1999-01-01","2000-01-01","2001-01-01","2002-01-01","2003-01-01","2004-01-01","2005-01-01","2007-01-01","2008-01-01","2009-01-01","2010-01-01","2011-01-01","2012-01-01","2013-01-01","2014-01-01","2015-01-01","2016-01-01"],"y":[41,52,46,47,39,49,44,31,31,33,27,36,32,38,26,33,27,32,14],"text":["1997<br />Republicans<br />Trust: 41%","1998<br />Republicans<br />Trust: 52%","1999<br />Republicans<br />Trust: 46%","2000<br />Republicans<br />Trust: 47%","2001<br />Republicans<br />Trust: 39%","2002<br />Republicans<br />Trust: 49%","2003<br />Republicans<br />Trust: 44%","2004<br />Republicans<br />Trust: 31%","2005<br />Republicans<br />Trust: 31%","2007<br />Republicans<br />Trust: 33%","2008<br />Republicans<br />Trust: 27%","2009<br />Republicans<br />Trust: 36%","2010<br />Republicans<br />Trust: 32%","2011<br />Republicans<br />Trust: 38%","2012<br />Republicans<br />Trust: 26%","2013<br />Republicans<br />Trust: 33%","2014<br />Republicans<br />Trust: 27%","2015<br />Republicans<br />Trust: 32%","2016<br />Republicans<br />Trust: 14%"],"type":"scatter","mode":"lines+markers","line":{"width":1.88976377952756,"color":"rgba(255,0,0,1)","dash":"solid"},"hoveron":"points","name":"Republicans","legendgroup":"Republicans","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","marker":{"autocolorscale":false,"color":"rgba(255,0,0,1)","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(255,0,0,1)"}},"frame":null},{"x":{},"y":{},"colour":{},"text":{},"type":"scatter","mode":"lines","hovertemplate":"NA","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null}],"layout":{"margin":{"t":43.7625570776256,"r":7.30593607305936,"b":40.1826484018265,"l":37.2602739726027},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":{"text":"Trust in Mass Media by Party","font":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"date","autorange":true,"range":["1996-01-20","2016-12-12"],"tickmode":"auto","ticktext":["2000","2005","2010","2015"],"tickvals":[10957,12784,14610,16436],"categoryorder":"array","categoryarray":["2000","2005","2010","2015"],"nticks":null,"ticks":"outside","tickcolor":"rgba(179,179,179,1)","ticklen":3.65296803652968,"tickwidth":0.33208800332088,"showticklabels":true,"tickfont":{"color":"rgba(119,119,119,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":true,"linecolor":"rgba(119,119,119,1)","linewidth":0.66417600664176,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.33208800332088,"zeroline":false,"anchor":"y","title":{"text":"Year","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":true,"range":[11.2,72.8],"tickmode":"auto","ticktext":["20","30","40","50","60","70"],"tickvals":[20,30,40,50,60,70],"categoryorder":"array","categoryarray":["20","30","40","50","60","70"],"nticks":null,"ticks":"outside","tickcolor":"rgba(179,179,179,1)","ticklen":3.65296803652968,"tickwidth":0.33208800332088,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(222,222,222,1)","gridwidth":0.33208800332088,"zeroline":false,"anchor":"x","title":{"text":"Trust (%)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(179,179,179,1)","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"x unified","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"56770d8da54":{"x":{},"y":{},"colour":{},"text":{},"type":"scatter"},"5672ce5faad":{"x":{},"y":{},"colour":{},"text":{}},"56770d8da54.1":{"x":{},"y":{},"colour":{},"text":{},"type":"scatter","mode":"lines","hovertemplate":"NA","inherit":true}},"cur_data":"56770d8da54","visdat":{"56770d8da54":["function (y) ","x"],"5672ce5faad":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Part of the problem with fake news is how easily it spreads. False information on Twitter is typically retweeted by many more people, and far more rapidly, than true information, especially when politics is the topic. This phenomenon of virality is hard to combat, as it is incredibly hard to find each person that was exposed to the falsehood and convince them of the truth. Surprisingly, robots accelerate the spread of true and false news at the same rate, implying that false news spreads more than truth because of humans <span class="citation">(<a href="#ref-vosoughi_2018" role="doc-biblioref">Vosoughi et al., 2018</a>)</span>. How can we prevent this spread, if we are the ones causing it?</p>
</div>
<div id="fact-checking" class="section level1">
<h1>Fact Checking</h1>
<p><img src="images/fact-checking.jpg" /></p>
<p>Fact checking has been adopted by many websites to evaluate the veracity of claims posted on the internet. Despite its prevalence, it struggles to combat the spread of fake news. This occurs for a couple of reasons. Individuals will only seek to explore a claim’s accuracy if it disagrees with their inner beliefs or they are incentivized to do so. Typically, readers ingest information without thinking critically about its source, especially on informal, social platforms. Further, people are prone to confirmation bias and desirability bias. They prefer information that confirms their preexisting beliefs, and are inclined to accept information that pleases them <span class="citation">(<a href="#ref-swift_2016" role="doc-biblioref">Swift, 2016</a>)</span>.</p>
<p>A study found that fact-checking might be counterproductive, as familiarity bias in politics has shown that people tend to remember information and how they feel about it rather than the context it was learned. By repeating the false claim, it might increase the reader’s likelihood of accepting it as true. By fact-checking a claim, you run the risk that it might be spread even further than if the claim were to fade away <span class="citation">(<a href="#ref-lewandowsky_2017" role="doc-biblioref">Lewandowsky et al., 2017</a>)</span>.</p>
<p>Another longer-term approach is to improve an individual’s ability to evaluate information sources. There has been an effort to teach critical-information skills to middle and high school students in the past few years. This can be especially helpful when the students are taught how information can be warped based on the perspective of who is presenting it. However, it is not yet clear whether these efforts are effective and if they will continue in the future <span class="citation">(<a href="#ref-jones_2017" role="doc-biblioref">Jones, 2017</a>)</span>.</p>
</div>
<div id="algorithmic-detection" class="section level1">
<h1>Algorithmic Detection</h1>
<p><img src="images/algo-fact-checking.jpg" /></p>
<p>The definition of fake news is quite simple in principle, but determining whether an article is false can be complex, even for humans. For the majority of articles, there is usually a mix of truthfulness and falsehood. The threshold for flagging a news article as fake news varies from reader to reader. Because of the political polarization leading up to and during the 2016 election, fake news became associated with a politician’s opposing viewpoint instead of false information. Additionally, there is content that does not contain falsehoods but is labeled as such because it attempts to persuade the reader, instead of inform.</p>
<p>There are those that argue that fake news should be defined as a continuum rather than a binary variable, as biased news exists somewhere in between fake and real. While it may be using real sources, the conclusions it draws might be dubious or opinionated. But it would be an exaggeration to call this fake news. Many fact-checking sites have a continuum like this, but again, these rely on humans and require a lot of time to ingest the vast amount of claims being published every day.</p>
<p>The best case is to create a model that is able to detect fake news before it is published, effectively stopping the spread before it causes damage. This approach is difficult to implement, and could impede the first amendment. Facebook and Google have been attempting to introduce a filter for fake news, but their attempts are still in their infancy and their platforms are still maintained by humans, who make many mistakes on their own. If a model could be successfully built, platforms such as Facebook or Twitter could vet links in posts before they are sent, effectively preventing the dissemination of misinformation.</p>
</div>
<div id="if-it-walks-like-a-duck" class="section level1">
<h1>If It Walks Like a Duck…</h1>
<p><a href="https://www.vangoghgallery.com/painting/starry-night.html"><img src="images/starry-night.jpg" alt="Vincent Van Gogh: Starry Night" /></a></p>
<p>Fact checking is a labor intensive process with no clear road to automation. If we want to build a model to accurately identify fake news without examining the actual claims that it makes, we can instead look at how the document is written.</p>
<p>Stylometry (greek <em>stylos</em> (style) + <em>metron</em> (measure)) is a method of studying linguistic style, and has been applied in a variety of fields from art (literature, music, painting) to security affairs and economics<span class="citation">(<a href="#ref-belak_2008" role="doc-biblioref">Belak et al., 2008</a>)</span>. Content is quite easy to copy (such as A Starry Night - while I could not paint a very good replica, I could get close enough for you to make the connection between the two paintings), imitating style is almost impossible. In art, techniques have been developed to distinguish details such as brush patterns, canvas thread count, and paint composition <span class="citation">(<a href="#ref-liu_2016" role="doc-biblioref">Liu et al., 2016</a>)</span>. Stylometric analysis in literature typically focuses on determining authorship, but could be extended here to determine the intuitive differences between real and fake news articles. Let’s take a look at a couple examples to see how they differ.</p>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<div id="source" class="section level2">
<h2>Source</h2>
<p>The data used in this article were combined from the collection of real/fake data scraped and labeled in <span class="citation">(<a href="#ref-dataset-origin" role="doc-biblioref">Ahmed et al., 2017</a>; <a href="#ref-random-news-dataset-origin" role="doc-biblioref">Horne &amp; Adali, 2017</a>; <a href="#ref-buzzfeed-dataset-origin" role="doc-biblioref">Silverman, 2016</a>)</span>. In total, it contains ~38,500 news articles with a title, body, and label included.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="distinguishing-differences" class="section level2">
<h2>Distinguishing Differences</h2>
<p>To get a better idea of what separates fake and real news, let’s look at the distinguishing words that each type uses and how common each is within the respective articles. The wordcloud below shows the difference between the words chosen between fake and real news articles. The size of each word is the relative frequency that it appears <em>against</em> the other document. That is to say, if fake news uses a word more than real news, it will appear on the fake news side, and its size will be determined by how many more times it was used, and how frequently other words were used. Let’s take a look.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/wordclouds-1.png" width="672" /></p>
<p>We can see that fake news mentions Trump, Obama, and Hillary more than real news. Real news seems to put more perspective into their articles, using words that imply a global view such as “minister,” “U.S.” “China,” and “Korea.” Additionally, we can see context clues that real news is time aware, frequently mentioning the day of the week such as “Tuesday,” “Wednesday,” and “Thursday.”</p>
<p>With this information, we can determine which words are more likely to be associated with fake and real news, and feed that into a model that will predict whether an article is real or fake. We will use Craig’s Zeta to gauge word preference between document types, a stylometric formula described by Burrows <span class="citation">(<a href="#ref-burrows_2006" role="doc-biblioref">Burrows, 2006</a>)</span>. As words approach the left side of the chart, they are used more in fake news, and as they approach the right side of the chart, they are used more in real news.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/craigs-zeta-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Overall, these words match with intuition. Fake news sensationalizes the information (hate, racist, truth, apparently) and real news speaks to a more global scale (ministry, region, trade, UN, negotiation). With these words, we can take the top 300 words and attempt to predict whether an article is true or not.</p>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>Overall, the model that was able to predict with <strong>95% accuracy</strong> whether a given article is fake or not. This is a great proof of concept that the future of disinformation protection looks more and more like algorithmically detecting fake news before it is spread, rather than fact checking.</p>
<p>There are a few caveats to this result, of course. The dataset is far from perfect – and is quite homogeneous (many of the articles are sources from the same couple news sites). A wide gamut of news articles needs to be tested to see if this methodology is effective. Additionally, the mere creation of a model such as this can create a feedback loop that results in the model performing poorly over time. This is more likely if the parameters are known to the fake news article writers, as they can change their style to avoid detection. This type of cat and mouse game will always be present, but especially with fake news and spam there will never be a perfect solution that works for every single case.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>As we progress into the next presidential election and more social media platforms are created and destroyed, the emphasis for dealing with fake news must shift from a reactive approach (fact checking) to a proactive approach (algorithmic detection) to effectively deal with the dissemination of false information. Those implementing these solutions must be careful to avoid censorship, but this line is present with any type of online or offline moderation of content.</p>
</div>
<div id="bibliography" class="section level1 unnumbered">
<h1>Bibliography</h1>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-dataset-origin" class="csl-entry">
Ahmed, H., Traore, I., &amp; Saad, S. (2017). Detecting opinion spams and fake news using text classification. <em>Security and Privacy</em>, <em>1</em>, e9. <a href="https://doi.org/10.1002/spy2.9">https://doi.org/10.1002/spy2.9</a>
</div>
<div id="ref-allcott_2017" class="csl-entry">
Allcott, H., &amp; Gentzkow, M. (2017). Social media and fake news in the 2016 election. <em>Journal of Economic Perspectives</em>, <em>31</em>(2), 211–236. <a href="https://doi.org/10.1257/jep.31.2.211">https://doi.org/10.1257/jep.31.2.211</a>
</div>
<div id="ref-belak_2008" class="csl-entry">
Belak, S., Radman Pesa, A., &amp; Belak, B. (2008). Stylometry–definition and development. <em>Annals of DAAAM <span>&amp;</span> Proceedings</em>, 85+. <a href="https://link.gale.com/apps/doc/A225316012/AONE?u=s8887317&amp;sid=googleScholar&amp;xid=c9e0d273">https://link.gale.com/apps/doc/A225316012/AONE?u=s8887317&amp;sid=googleScholar&amp;xid=c9e0d273</a>
</div>
<div id="ref-burrows_2006" class="csl-entry">
Burrows, J. (2006). <span class="nocase">All the Way Through: Testing for Authorship in Different Frequency Strata</span>. <em>Literary and Linguistic Computing</em>, <em>22</em>(1), 27–47. <a href="https://doi.org/10.1093/llc/fqi067">https://doi.org/10.1093/llc/fqi067</a>
</div>
<div id="ref-random-news-dataset-origin" class="csl-entry">
Horne, B. D., &amp; Adali, S. (2017). <em>This just in: Fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news</em>. <a href="http://arxiv.org/abs/1703.09398">http://arxiv.org/abs/1703.09398</a>
</div>
<div id="ref-jones_2017" class="csl-entry">
Jones, C. (2017). <em>Bill would help california schools teach about <span>“fake news,”</span> media literacy</em>. <a href="https://edsource.org/2017/bill-would-help-california-schools-teach-about-fake-news-media-literacy/58236">https://edsource.org/2017/bill-would-help-california-schools-teach-about-fake-news-media-literacy/58236</a>
</div>
<div id="ref-lazer_2018" class="csl-entry">
Lazer, D. M. J., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F., Metzger, M. J., Nyhan, B., Pennycook, G., Rothschild, D., Schudson, M., Sloman, S. A., Sunstein, C. R., Thorson, E. A., Watts, D. J., &amp; Zittrain, J. L. (2018). The science of fake news. <em>Science (American Association for the Advancement of Science)</em>, <em>359</em>(6380), 1094–1096. <a href="https://doi.org/10.1126/science.aao2998">https://doi.org/10.1126/science.aao2998</a>
</div>
<div id="ref-lewandowsky_2017" class="csl-entry">
Lewandowsky, S., Ecker, U. K. H., &amp; Cook, J. (2017). Beyond misinformation: Understanding and coping with the <span>“post-truth”</span> era. <em>Journal of Applied Research in Memory and Cognition</em>, <em>6</em>(4), 353–369. https://doi.org/<a href="https://doi.org/10.1016/j.jarmac.2017.07.008">https://doi.org/10.1016/j.jarmac.2017.07.008</a>
</div>
<div id="ref-liu_2016" class="csl-entry">
Liu, H., Chan, R. H., &amp; Yao, Y. (2016). Geometric tight frame based stylometry for art authentication of van gogh paintings. <em>Applied and Computational Harmonic Analysis</em>, <em>41</em>(2), 590–602. https://doi.org/<a href="https://doi.org/10.1016/j.acha.2015.11.005">https://doi.org/10.1016/j.acha.2015.11.005</a>
</div>
<div id="ref-shearer_2017" class="csl-entry">
Shearer, E., &amp; Gottfried, J. (2017). <em>News use across social media platforms 2017</em>. <a href="https://www.journalism.org/2017/09/07/news-use-across-social-media-platforms-2017/">https://www.journalism.org/2017/09/07/news-use-across-social-media-platforms-2017/</a>
</div>
<div id="ref-buzzfeed-dataset-origin" class="csl-entry">
Silverman, C. (2016). <em>This analysis shows how viral fake election news stories outperformed real news on facebook</em>. <a href="https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook">https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook</a>
</div>
<div id="ref-swift_2016" class="csl-entry">
Swift, A. (2016). Americans’ trust in mass media sinks to new low. In <em>Gallup News</em>. Gallup, Inc. <a href="https://news.gallup.com/poll/195542/americans-trust-mass-media-sinks-new-low.aspx">https://news.gallup.com/poll/195542/americans-trust-mass-media-sinks-new-low.aspx</a>
</div>
<div id="ref-vosoughi_2018" class="csl-entry">
Vosoughi, S., Roy, D., &amp; Aral, S. (2018). The spread of true and false news online. <em>Science (American Association for the Advancement of Science)</em>, <em>359</em>(6380), 1146–1151. <a href="https://doi.org/10.1126/science.aap9559">https://doi.org/10.1126/science.aap9559</a>
</div>
</div>
</div>
